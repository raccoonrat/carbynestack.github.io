{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"getting-started/","text":"Getting Started with Carbyne Stack \u00b6 The tutorials in this section will walk you through the basics of the Carbyne Stack Native MPC platform and how to set up and run simple experiments with it. You will Understand the basic architecture and abstractions of the Carbyne Stack platform. Set up Kubernetes clusters with all the prerequisites required for deploying a Carbyne Stack Virtual Cloud Provider including Istio and Knative. Deploy a fully functional Carbyne Stack Virtual Cloud to these clusters. Learn how to solve the canonical Millionaires Problem leveraging the Carbyne Stack CLI . Tip Have fun and let us know in case you encounter any obstacles or problems.","title":"Getting Started with Carbyne Stack"},{"location":"getting-started/#getting-started-with-carbyne-stack","text":"The tutorials in this section will walk you through the basics of the Carbyne Stack Native MPC platform and how to set up and run simple experiments with it. You will Understand the basic architecture and abstractions of the Carbyne Stack platform. Set up Kubernetes clusters with all the prerequisites required for deploying a Carbyne Stack Virtual Cloud Provider including Istio and Knative. Deploy a fully functional Carbyne Stack Virtual Cloud to these clusters. Learn how to solve the canonical Millionaires Problem leveraging the Carbyne Stack CLI . Tip Have fun and let us know in case you encounter any obstacles or problems.","title":"Getting Started with Carbyne Stack"},{"location":"getting-started/deployment/","text":"Stack Deployment Guide \u00b6 This guide describes how to set up a Carbyne Stack Virtual Cloud (VC) consisting of two Virtual Cloud Providers (VCP). Prerequisites \u00b6 Warning Carbyne Stack has been tested using the exact versions of the tools specified below. Deviating from this battle tested configuration may create all kinds of issues. Helmfile v0.142.0 Helm v3.7.1 Helm Diff Plugin v3.1.3 In addition, this guide assumes you have access to two properly configured K8s clusters (herein referred to as apollo and starbuck ) with the following components: Kubernetes v1.18.19 Istio v1.7.3 MetalLB v0.9.3 Knative v0.19.0 Zalando Postgres Operator v1.5.0 Throughout the remainder of this guide, we assume that you have set up local clusters using the kind tool as described in the Platform Setup guide. Virtual Cloud Deployment \u00b6 Tip In case you are on a slow internet connection, you can use kind load docker-image <image> --name <cluster-name> to load images from your local docker registry into the kind clusters. This way you have to download the images only once and then reuse them across VCP deployments. Checkout out the carbynestack repository and descend into the repository root directory using: HTTP SSH git clone https://github.com/carbynestack/carbynestack.git cd carbynestack git clone git@github.com:carbynestack/carbynestack.git cd carbynestack Before deploying the virtual cloud providers make some common configuration available using: Attention Replace 172.18.1.128 and 172.18.2.128 with the load balancer IPs assigned to the Istio Ingress Gateway by MetalLB (see the Platform Setup guide). export APOLLO_FQDN = \"172.18.1.128.sslip.io\" export STARBUCK_FQDN = \"172.18.2.128.sslip.io\" export RELEASE_NAME = cs export DISCOVERY_MASTER_HOST = $APOLLO_FQDN export NO_SSL_VALIDATION = true Launch the starbuck VCP using: export FRONTEND_URL = $STARBUCK_FQDN export IS_MASTER = false export AMPHORA_VC_PARTNER_URI = http:// $APOLLO_FQDN /amphora kubectl config use-context kind-starbuck helmfile apply Launch the apollo VCP using: export FRONTEND_URL = $APOLLO_FQDN export IS_MASTER = true export AMPHORA_VC_PARTNER_URI = http:// $STARBUCK_FQDN /amphora export CASTOR_SLAVE_URI = http:// $STARBUCK_FQDN /castor kubectl config use-context kind-apollo helmfile apply Wait until all pods in both clusters are in the ready state. Preparing the Virtual Cloud \u00b6 Carbyne Stack comes with a CLI that can be used to interact with a virtual cloud from the command line. Install the CLI using: export CLI_VERSION = 0 .1-SNAPSHOT-1576571202-7-cf3db5b curl -o cs.jar -L https://github.com/carbynestack/cli/releases/download/ $CLI_VERSION /cli- $CLI_VERSION -jar-with-dependencies.jar Next configure the CLI to talk to the just deployed virtual cloud by creating a matching CLI configuration file in ~/.cs using: mkdir -p ~/.cs cat <<EOF | envsubst > ~/.cs/config { \"prime\" : 198766463529478683931867765928436695041, \"r\" : 141515903391459779531506841503331516415, \"noSslValidation\" : true, \"trustedCertificates\" : [ ], \"providers\" : [ { \"amphoraServiceUrl\" : \"http://$APOLLO_FQDN/amphora\", \"castorServiceUrl\" : \"http://$APOLLO_FQDN/castor\", \"ephemeralServiceUrl\" : \"http://$APOLLO_FQDN/\", \"id\" : 1, \"baseUrl\" : \"http://$APOLLO_FQDN/\" }, { \"amphoraServiceUrl\" : \"http://$STARBUCK_FQDN/amphora\", \"castorServiceUrl\" : \"http://$STARBUCK_FQDN/castor\", \"ephemeralServiceUrl\" : \"http://$STARBUCK_FQDN/\", \"id\" : 2, \"baseUrl\" : \"http://$STARBUCK_FQDN/\" } ], \"rinv\" : 133854242216446749056083838363708373830 } EOF Alternatively, you can use the CLI tool itself to do the configuration by providing the respective values (as seen above in the HEREDOC) when asked using: java -jar cs.jar configure You can verify that the configuration works by fetching telemetry data from castor using: Attention Replace <#> with either 1 for the apollo cluster or 2 for the starbuck cluster. java -jar cs.jar castor get-telemetry < #> Upload Offline Material \u00b6 Before you can actually use the services provided by the Virtual Cloud, you have to upload cryptographic material. As generating offline material is a very time-consuming process, we provide pre-generated material. Danger Using pre-generated offline material is not secure at all. DO NOT DO THIS IN A PRODUCTION SETTING . Download and decompress the archive containing the material using: curl -O -L https://raw.githubusercontent.com/carbynestack/base-images/master/fake-crypto-material.zip unzip -d crypto-material fake-crypto-material.zip rm fake-crypto-material.zip Upload and activate tuples using: Tip Adapt the NUMBER_OF_CHUNKS variable in the following snippet to tune the number of uploaded tuples. In case NUMBER_OF_CHUNKS > 1 the same tuples are uploaded repeatedly. cat << 'EOF' > upload-tuples.sh #!/bin/bash SCRIPT_PATH=\"$( cd \"$(dirname \"$0\")\" ; pwd -P )\" TUPLE_FOLDER=${SCRIPT_PATH}/crypto-material/2-128-40 CLI_PATH=${SCRIPT_PATH} NUMBER_OF_CHUNKS=1 function uploadTuples { echo ${NUMBER_OF_CHUNKS} for type in INPUT_MASK_GFP MULTIPLICATION_TRIPLE_GFP; do for (( i=0; i<${NUMBER_OF_CHUNKS}; i++ )); do local chunkId=$(uuidgen) echo \"Uploading ${type} to http://${APOLLO_FQDN}/castor (Apollo)\" java -jar ${CLI_PATH}/cs.jar castor upload-tuple -f ${TUPLE_FOLDER}/Triples-p-P0 -t ${type} -i ${chunkId} 1 local statusMaster=$? echo \"Uploading ${type} to http://${STARBUCK_FQDN}/castor (Starbuck)\" java -jar ${CLI_PATH}/cs.jar castor upload-tuple -f ${TUPLE_FOLDER}/Triples-p-P1 -t ${type} -i ${chunkId} 2 local statusSlave=$? if [[ \"${statusMaster}\" -eq 0 && \"${statusSlave}\" -eq 0 ]]; then java -jar ${CLI_PATH}/cs.jar castor activate-chunk -i ${chunkId} 1 java -jar ${CLI_PATH}/cs.jar castor activate-chunk -i ${chunkId} 2 else echo \"ERROR: Failed to upload one tuple chunk - not activated\" fi done done } uploadTuples EOF chmod 755 upload-tuples.sh ./upload-tuples.sh You can verify that the uploaded tuples are now available for use by the Carbyne Stack services using: Attention Replace <#> with either 1 for the apollo cluster or 2 for the starbuck cluster. java -jar cs.jar castor get-telemetry < #> You now have a fully functional Carbyne Stack Virtual Cloud at your hands. Teardown the Virtual Cloud \u00b6 You can tear down the Virtual Cloud by tearing down the Virtual Cloud Providers using: for var in apollo starbuck do kubectl config use-context kind- $var helmfile destroy done","title":"Stack Deployment"},{"location":"getting-started/deployment/#stack-deployment-guide","text":"This guide describes how to set up a Carbyne Stack Virtual Cloud (VC) consisting of two Virtual Cloud Providers (VCP).","title":"Stack Deployment Guide"},{"location":"getting-started/deployment/#prerequisites","text":"Warning Carbyne Stack has been tested using the exact versions of the tools specified below. Deviating from this battle tested configuration may create all kinds of issues. Helmfile v0.142.0 Helm v3.7.1 Helm Diff Plugin v3.1.3 In addition, this guide assumes you have access to two properly configured K8s clusters (herein referred to as apollo and starbuck ) with the following components: Kubernetes v1.18.19 Istio v1.7.3 MetalLB v0.9.3 Knative v0.19.0 Zalando Postgres Operator v1.5.0 Throughout the remainder of this guide, we assume that you have set up local clusters using the kind tool as described in the Platform Setup guide.","title":"Prerequisites"},{"location":"getting-started/deployment/#virtual-cloud-deployment","text":"Tip In case you are on a slow internet connection, you can use kind load docker-image <image> --name <cluster-name> to load images from your local docker registry into the kind clusters. This way you have to download the images only once and then reuse them across VCP deployments. Checkout out the carbynestack repository and descend into the repository root directory using: HTTP SSH git clone https://github.com/carbynestack/carbynestack.git cd carbynestack git clone git@github.com:carbynestack/carbynestack.git cd carbynestack Before deploying the virtual cloud providers make some common configuration available using: Attention Replace 172.18.1.128 and 172.18.2.128 with the load balancer IPs assigned to the Istio Ingress Gateway by MetalLB (see the Platform Setup guide). export APOLLO_FQDN = \"172.18.1.128.sslip.io\" export STARBUCK_FQDN = \"172.18.2.128.sslip.io\" export RELEASE_NAME = cs export DISCOVERY_MASTER_HOST = $APOLLO_FQDN export NO_SSL_VALIDATION = true Launch the starbuck VCP using: export FRONTEND_URL = $STARBUCK_FQDN export IS_MASTER = false export AMPHORA_VC_PARTNER_URI = http:// $APOLLO_FQDN /amphora kubectl config use-context kind-starbuck helmfile apply Launch the apollo VCP using: export FRONTEND_URL = $APOLLO_FQDN export IS_MASTER = true export AMPHORA_VC_PARTNER_URI = http:// $STARBUCK_FQDN /amphora export CASTOR_SLAVE_URI = http:// $STARBUCK_FQDN /castor kubectl config use-context kind-apollo helmfile apply Wait until all pods in both clusters are in the ready state.","title":"Virtual Cloud Deployment"},{"location":"getting-started/deployment/#preparing-the-virtual-cloud","text":"Carbyne Stack comes with a CLI that can be used to interact with a virtual cloud from the command line. Install the CLI using: export CLI_VERSION = 0 .1-SNAPSHOT-1576571202-7-cf3db5b curl -o cs.jar -L https://github.com/carbynestack/cli/releases/download/ $CLI_VERSION /cli- $CLI_VERSION -jar-with-dependencies.jar Next configure the CLI to talk to the just deployed virtual cloud by creating a matching CLI configuration file in ~/.cs using: mkdir -p ~/.cs cat <<EOF | envsubst > ~/.cs/config { \"prime\" : 198766463529478683931867765928436695041, \"r\" : 141515903391459779531506841503331516415, \"noSslValidation\" : true, \"trustedCertificates\" : [ ], \"providers\" : [ { \"amphoraServiceUrl\" : \"http://$APOLLO_FQDN/amphora\", \"castorServiceUrl\" : \"http://$APOLLO_FQDN/castor\", \"ephemeralServiceUrl\" : \"http://$APOLLO_FQDN/\", \"id\" : 1, \"baseUrl\" : \"http://$APOLLO_FQDN/\" }, { \"amphoraServiceUrl\" : \"http://$STARBUCK_FQDN/amphora\", \"castorServiceUrl\" : \"http://$STARBUCK_FQDN/castor\", \"ephemeralServiceUrl\" : \"http://$STARBUCK_FQDN/\", \"id\" : 2, \"baseUrl\" : \"http://$STARBUCK_FQDN/\" } ], \"rinv\" : 133854242216446749056083838363708373830 } EOF Alternatively, you can use the CLI tool itself to do the configuration by providing the respective values (as seen above in the HEREDOC) when asked using: java -jar cs.jar configure You can verify that the configuration works by fetching telemetry data from castor using: Attention Replace <#> with either 1 for the apollo cluster or 2 for the starbuck cluster. java -jar cs.jar castor get-telemetry < #>","title":"Preparing the Virtual Cloud"},{"location":"getting-started/deployment/#upload-offline-material","text":"Before you can actually use the services provided by the Virtual Cloud, you have to upload cryptographic material. As generating offline material is a very time-consuming process, we provide pre-generated material. Danger Using pre-generated offline material is not secure at all. DO NOT DO THIS IN A PRODUCTION SETTING . Download and decompress the archive containing the material using: curl -O -L https://raw.githubusercontent.com/carbynestack/base-images/master/fake-crypto-material.zip unzip -d crypto-material fake-crypto-material.zip rm fake-crypto-material.zip Upload and activate tuples using: Tip Adapt the NUMBER_OF_CHUNKS variable in the following snippet to tune the number of uploaded tuples. In case NUMBER_OF_CHUNKS > 1 the same tuples are uploaded repeatedly. cat << 'EOF' > upload-tuples.sh #!/bin/bash SCRIPT_PATH=\"$( cd \"$(dirname \"$0\")\" ; pwd -P )\" TUPLE_FOLDER=${SCRIPT_PATH}/crypto-material/2-128-40 CLI_PATH=${SCRIPT_PATH} NUMBER_OF_CHUNKS=1 function uploadTuples { echo ${NUMBER_OF_CHUNKS} for type in INPUT_MASK_GFP MULTIPLICATION_TRIPLE_GFP; do for (( i=0; i<${NUMBER_OF_CHUNKS}; i++ )); do local chunkId=$(uuidgen) echo \"Uploading ${type} to http://${APOLLO_FQDN}/castor (Apollo)\" java -jar ${CLI_PATH}/cs.jar castor upload-tuple -f ${TUPLE_FOLDER}/Triples-p-P0 -t ${type} -i ${chunkId} 1 local statusMaster=$? echo \"Uploading ${type} to http://${STARBUCK_FQDN}/castor (Starbuck)\" java -jar ${CLI_PATH}/cs.jar castor upload-tuple -f ${TUPLE_FOLDER}/Triples-p-P1 -t ${type} -i ${chunkId} 2 local statusSlave=$? if [[ \"${statusMaster}\" -eq 0 && \"${statusSlave}\" -eq 0 ]]; then java -jar ${CLI_PATH}/cs.jar castor activate-chunk -i ${chunkId} 1 java -jar ${CLI_PATH}/cs.jar castor activate-chunk -i ${chunkId} 2 else echo \"ERROR: Failed to upload one tuple chunk - not activated\" fi done done } uploadTuples EOF chmod 755 upload-tuples.sh ./upload-tuples.sh You can verify that the uploaded tuples are now available for use by the Carbyne Stack services using: Attention Replace <#> with either 1 for the apollo cluster or 2 for the starbuck cluster. java -jar cs.jar castor get-telemetry < #> You now have a fully functional Carbyne Stack Virtual Cloud at your hands.","title":"Upload Offline Material"},{"location":"getting-started/deployment/#teardown-the-virtual-cloud","text":"You can tear down the Virtual Cloud by tearing down the Virtual Cloud Providers using: for var in apollo starbuck do kubectl config use-context kind- $var helmfile destroy done","title":"Teardown the Virtual Cloud"},{"location":"getting-started/millionaires/","text":"Solving the Millionaires Problem \u00b6 In this tutorial, you will learn how to solve the millionaires problem using an MPC function deployed on Carbyne Stack. Prerequisites \u00b6 You need a deployed Carbyne Stack Virtual Cloud and the Carbyne Stack CLI. Please see the Platform Setup Guide and the Deployment Guide for instructions on how to get hold of these. In addition, this guide assumes that you have the following tools installed: Java 8 (newer versions will not work) The Billionaires Problem \u00b6 We use a variation of Andrew Yao's Millionaires' Problem that is the secure multi-party computation problem of deciding which of two millionaires, Alice and Bob, is richer without revealing their actual wealth. Since the conception of the problem, the world has moved on and we better speak today not of two millionaires but of two (completely fictional) billionaires called Jeff and Elon. In the following, we describe how to solve this problem using Carbyne Stack. To see how things work, let's put ourselves in Elon's shoes. Providing the Inputs \u00b6 First, we upload the inputs into the Carbyne Stack Amphora Secret Store . The inputs are the billionaires' net worth in billions. Note that this obviously has to be done in a private way by Jeff and Elon in a real-world setting. # Create a secret representing Jeff's net worth (note that we work with # billion USD here) export JEFFS_NET_WORTH_ID = $( java -jar cs.jar amphora create-secret 177 -t billionaire = Jeff ) # And another one for Elon export ELONS_NET_WORTH_ID = $( java -jar cs.jar amphora create-secret 151 -t billionaire = Elon ) We can check the secrets have been created using: java -jar cs.jar amphora get-secrets The output should resemble the following: Note The output you see will differ wrt. identifiers and the creation-date tag. ab160f93-3b7e-468f-b687-f9c46fb535f3 billionaire -> Jeff creation-date -> 1630660117946 ef3e867f-9233-46fb-9cde-7a09c99bc32f billionaire -> Elon creation-date -> 1630660125951 Invoke the Billionaires Function \u00b6 Elon is eager to see whether he ranks first in the list of the richest people in the world. To check that using the Carbyne Stack platform, a well-known global media company which regularly publishes a list of the richest people in the world came up with the following MP-SPDZ program that does the job: cat << 'EOF' > billionaires.mpc # Prologue to read in the inputs listen(10000) socket_id = regint() acceptclientconnection(socket_id, 10000) v = sint.read_from_socket(socket_id, 2) # The logic first_billionaires_net_worth = v[0] second_billionaires_net_worth= v[1] result = first_billionaires_net_worth < second_billionaires_net_worth # Epilogue to return the outputs resp = Array(1, sint) resp[0] = result sint.write_to_socket(socket_id, resp) EOF The program expects two inputs and does a simple comparison between them. The result written as a secret to Amphora at the end of the program is either 1 in case the first input is less than the second or 0 otherwise. Elon invokes the program using the Ephemeral Serverless Compute Service as follows: export RESULT_ID = $( cat billionaires.mpc | java -jar cs.jar ephemeral execute \\ -i $JEFFS_NET_WORTH_ID \\ -i $ELONS_NET_WORTH_ID \\ ephemeral-generic.default \\ | tail -n +2 \\ | sed 's/[][]//g' ) The CLI spits out a list of identifiers of Amphora Secrets generated by the program. The snippet above extracts the single identifier emitted in this example and stores it in the RESULT_ID shell variable. Using this identifier Elon can inspect the result of the execution using: java -jar cs.jar amphora get-secret $RESULT_ID The output being 0 tells Elon that unfortunately Jeff is still the alpha: [ 0 ] creation-date -> 1630661192626 gameID -> 7899b23c-4509-4ff8-a9ae-d9b59fa77fea After buying a bunch of the fabulous new (and completely fictional) Carbyne Stack Altcoins and posting a tweet that one of his companies will accept that coin for payments in the future, Elon wants to see whether he is finally in the pole position. He deletes his old and submits his new net worth and triggers the evaluation of the Billionaires Problem logic again using: java -jar cs.jar amphora delete-secrets $ELONS_NET_WORTH_ID export ELONS_NET_WORTH_ID = $( java -jar cs.jar amphora create-secret 179 -t billionaire = Elon ) export RESULT_ID = $( cat billionaires.mpc | java -jar cs.jar ephemeral execute \\ -i $JEFFS_NET_WORTH_ID \\ -i $ELONS_NET_WORTH_ID \\ ephemeral-generic.default \\ | tail -n +2 \\ | sed 's/[][]//g' ) java -jar cs.jar amphora get-secret $RESULT_ID This time the execution results in a '1', which creates a pleasantly warm feeling in Elon's chest. Next Steps \u00b6 This simple tutorial showcased only a small subset of the Carbyne Stack's capabilities. Feel free to explore the possibilities yourself by playing around with the CLI.","title":"Millionaires Problem"},{"location":"getting-started/millionaires/#solving-the-millionaires-problem","text":"In this tutorial, you will learn how to solve the millionaires problem using an MPC function deployed on Carbyne Stack.","title":"Solving the Millionaires Problem"},{"location":"getting-started/millionaires/#prerequisites","text":"You need a deployed Carbyne Stack Virtual Cloud and the Carbyne Stack CLI. Please see the Platform Setup Guide and the Deployment Guide for instructions on how to get hold of these. In addition, this guide assumes that you have the following tools installed: Java 8 (newer versions will not work)","title":"Prerequisites"},{"location":"getting-started/millionaires/#the-billionaires-problem","text":"We use a variation of Andrew Yao's Millionaires' Problem that is the secure multi-party computation problem of deciding which of two millionaires, Alice and Bob, is richer without revealing their actual wealth. Since the conception of the problem, the world has moved on and we better speak today not of two millionaires but of two (completely fictional) billionaires called Jeff and Elon. In the following, we describe how to solve this problem using Carbyne Stack. To see how things work, let's put ourselves in Elon's shoes.","title":"The Billionaires Problem"},{"location":"getting-started/millionaires/#providing-the-inputs","text":"First, we upload the inputs into the Carbyne Stack Amphora Secret Store . The inputs are the billionaires' net worth in billions. Note that this obviously has to be done in a private way by Jeff and Elon in a real-world setting. # Create a secret representing Jeff's net worth (note that we work with # billion USD here) export JEFFS_NET_WORTH_ID = $( java -jar cs.jar amphora create-secret 177 -t billionaire = Jeff ) # And another one for Elon export ELONS_NET_WORTH_ID = $( java -jar cs.jar amphora create-secret 151 -t billionaire = Elon ) We can check the secrets have been created using: java -jar cs.jar amphora get-secrets The output should resemble the following: Note The output you see will differ wrt. identifiers and the creation-date tag. ab160f93-3b7e-468f-b687-f9c46fb535f3 billionaire -> Jeff creation-date -> 1630660117946 ef3e867f-9233-46fb-9cde-7a09c99bc32f billionaire -> Elon creation-date -> 1630660125951","title":"Providing the Inputs"},{"location":"getting-started/millionaires/#invoke-the-billionaires-function","text":"Elon is eager to see whether he ranks first in the list of the richest people in the world. To check that using the Carbyne Stack platform, a well-known global media company which regularly publishes a list of the richest people in the world came up with the following MP-SPDZ program that does the job: cat << 'EOF' > billionaires.mpc # Prologue to read in the inputs listen(10000) socket_id = regint() acceptclientconnection(socket_id, 10000) v = sint.read_from_socket(socket_id, 2) # The logic first_billionaires_net_worth = v[0] second_billionaires_net_worth= v[1] result = first_billionaires_net_worth < second_billionaires_net_worth # Epilogue to return the outputs resp = Array(1, sint) resp[0] = result sint.write_to_socket(socket_id, resp) EOF The program expects two inputs and does a simple comparison between them. The result written as a secret to Amphora at the end of the program is either 1 in case the first input is less than the second or 0 otherwise. Elon invokes the program using the Ephemeral Serverless Compute Service as follows: export RESULT_ID = $( cat billionaires.mpc | java -jar cs.jar ephemeral execute \\ -i $JEFFS_NET_WORTH_ID \\ -i $ELONS_NET_WORTH_ID \\ ephemeral-generic.default \\ | tail -n +2 \\ | sed 's/[][]//g' ) The CLI spits out a list of identifiers of Amphora Secrets generated by the program. The snippet above extracts the single identifier emitted in this example and stores it in the RESULT_ID shell variable. Using this identifier Elon can inspect the result of the execution using: java -jar cs.jar amphora get-secret $RESULT_ID The output being 0 tells Elon that unfortunately Jeff is still the alpha: [ 0 ] creation-date -> 1630661192626 gameID -> 7899b23c-4509-4ff8-a9ae-d9b59fa77fea After buying a bunch of the fabulous new (and completely fictional) Carbyne Stack Altcoins and posting a tweet that one of his companies will accept that coin for payments in the future, Elon wants to see whether he is finally in the pole position. He deletes his old and submits his new net worth and triggers the evaluation of the Billionaires Problem logic again using: java -jar cs.jar amphora delete-secrets $ELONS_NET_WORTH_ID export ELONS_NET_WORTH_ID = $( java -jar cs.jar amphora create-secret 179 -t billionaire = Elon ) export RESULT_ID = $( cat billionaires.mpc | java -jar cs.jar ephemeral execute \\ -i $JEFFS_NET_WORTH_ID \\ -i $ELONS_NET_WORTH_ID \\ ephemeral-generic.default \\ | tail -n +2 \\ | sed 's/[][]//g' ) java -jar cs.jar amphora get-secret $RESULT_ID This time the execution results in a '1', which creates a pleasantly warm feeling in Elon's chest.","title":"Invoke the Billionaires Function"},{"location":"getting-started/millionaires/#next-steps","text":"This simple tutorial showcased only a small subset of the Carbyne Stack's capabilities. Feel free to explore the possibilities yourself by playing around with the CLI.","title":"Next Steps"},{"location":"getting-started/overview/","text":"Overview \u00b6 This guide describes the basic architecture and fundamental abstractions of the Carbyne Stack platform. Client/Server-style MPC \u00b6 Secure Multiparty Computation (MPC) is a cryptographic technique that distributes a computation among multiple parties in such a way that no single party can see the other parties' data. Carbyne Stack implements SPDZ-like (see [1]) MPC in the client/server model, first described by Damg\u00e5rd et al. in [2]. In this variant of MPC, computations are offloaded by clients to a set of servers that act as the MPC parties. Translated to the Carbyne Stack universe, this means, we can have a set of Carbyne Stack deployments acting as the MPC parties 1 and any number of clients invoking the services provided collectively by the Carbyne Stack deployments. In Carbyne Stack lingo, we refer to the MPC parties as Virtual Cloud Providers (VCPs) that jointly provide MPC services in a Virtual Cloud (VC). Carbyne Stack Services \u00b6 Each VCP hosts a set of elementary services called Castor , Amphora , and Ephemeral that together implement a fully functional cloud-native MPC party ( see Figure 1): Castor stores data-independent tuples generated in the MPC offline phase 2 and serves them on request to Amphora and Ephemeral. Amphora is the secret store that is used by clients to store and retrieve secrets. Secrets are stored as secret shares on the distributed Amphora instances in a VC. They can be used as inputs to an Ephemeral computation or are created as results of such a computation. Amphora uses data-independent tuples from Castor to facilitate secure up-/download in the client/server setting as described in [1]. Ephemeral is used to execute programs using the MP-SPDZ MPC framework. Any number of secrets can be fetched from Amphora at the beginning of an MPC program execution and any number of secrets can be written to Amphora at the end. Ephemeral fetches tuples from Castor consumed throughout the execution of the MPC program. Figure 1: Carbyne Stack comprising the data store and compute services, clients, and a CLI Communication Interfaces \u00b6 The VCP services interact locally, with their counterparts in other VCPs, and with clients (see Figure 2). There are three communication interfaces involved: The Intra-VCP Interface is used to communicate internally within a VCP. For example, Ephemeral talks to the co-located Castor service to fetch offline tuples using the intra-vcp interface 3 . The Inter-VCP Interface is used to coordinate operations among VCPs. An example for this is the interaction required between Amphora instances to perform the secure up-/download protocols mentioned above. The Client Interface is used by clients to invoke the Carbyne Stack services provided by a VC, e.g., uploading a secret to Amphora or triggering an MPC program execution via Ephemeral. Figure 2: The Carbyne stack components and the interfaces through which they communicate Scalability \u00b6 A central design goal of Carbyne Stack is that each of the VCP services can be scaled independently and automatically. To achieve this, the Carbyne Stack microservices are implemented as Kubernetes services (Castor and Amphora) and as Knative applications (Ephemeral). This allows the scaling mechanisms of these platforms to be used to react dynamically to fluctuating load patterns. Bibliography \u00b6 [1] Ivan Damg\u00e5rd, Valerio Pastro, Nigel Smart, Sarah Zakarias: Multiparty computation from somewhat homomorphic encryption . In: Safavi-Naini, R., Canetti, R. (eds.) Advances in Cryptology \u2013 CRYPTO 2012. Lecture Notes in Computer Science, vol. 7417, pp. 643\u2013662. Springer, Heidelberg, Germany, Santa Barbara, CA, USA (Aug 19\u201323, 2012) [2] Ivan Damg\u00e5rd, Kasper Damg\u00e5rd, Kurt Nielsen, Peter Sebastian Nordholt, Tomas Toft: Confidential Benchmarking based on Multiparty Computation . In Grossklags, J. and Preneel, B. (eds.) Financial Cryptography and Data Security, pp.169\u2013187. Springer. Only two-party settings are supported by Carbyne Stack as of now. \u21a9 Tuples must be generated externally and uploaded using the CLI as of today. A future release of Carbyne Stack will include a service called Klyshko to generate tuples in a scalable manner. \u21a9 Note that currently tuples baked into the container image are used by Ephemeral. Fetching the tuples from Castor will be implemented in a future release. \u21a9","title":"Overview"},{"location":"getting-started/overview/#overview","text":"This guide describes the basic architecture and fundamental abstractions of the Carbyne Stack platform.","title":"Overview"},{"location":"getting-started/overview/#clientserver-style-mpc","text":"Secure Multiparty Computation (MPC) is a cryptographic technique that distributes a computation among multiple parties in such a way that no single party can see the other parties' data. Carbyne Stack implements SPDZ-like (see [1]) MPC in the client/server model, first described by Damg\u00e5rd et al. in [2]. In this variant of MPC, computations are offloaded by clients to a set of servers that act as the MPC parties. Translated to the Carbyne Stack universe, this means, we can have a set of Carbyne Stack deployments acting as the MPC parties 1 and any number of clients invoking the services provided collectively by the Carbyne Stack deployments. In Carbyne Stack lingo, we refer to the MPC parties as Virtual Cloud Providers (VCPs) that jointly provide MPC services in a Virtual Cloud (VC).","title":"Client/Server-style MPC"},{"location":"getting-started/overview/#carbyne-stack-services","text":"Each VCP hosts a set of elementary services called Castor , Amphora , and Ephemeral that together implement a fully functional cloud-native MPC party ( see Figure 1): Castor stores data-independent tuples generated in the MPC offline phase 2 and serves them on request to Amphora and Ephemeral. Amphora is the secret store that is used by clients to store and retrieve secrets. Secrets are stored as secret shares on the distributed Amphora instances in a VC. They can be used as inputs to an Ephemeral computation or are created as results of such a computation. Amphora uses data-independent tuples from Castor to facilitate secure up-/download in the client/server setting as described in [1]. Ephemeral is used to execute programs using the MP-SPDZ MPC framework. Any number of secrets can be fetched from Amphora at the beginning of an MPC program execution and any number of secrets can be written to Amphora at the end. Ephemeral fetches tuples from Castor consumed throughout the execution of the MPC program. Figure 1: Carbyne Stack comprising the data store and compute services, clients, and a CLI","title":"Carbyne Stack Services"},{"location":"getting-started/overview/#communication-interfaces","text":"The VCP services interact locally, with their counterparts in other VCPs, and with clients (see Figure 2). There are three communication interfaces involved: The Intra-VCP Interface is used to communicate internally within a VCP. For example, Ephemeral talks to the co-located Castor service to fetch offline tuples using the intra-vcp interface 3 . The Inter-VCP Interface is used to coordinate operations among VCPs. An example for this is the interaction required between Amphora instances to perform the secure up-/download protocols mentioned above. The Client Interface is used by clients to invoke the Carbyne Stack services provided by a VC, e.g., uploading a secret to Amphora or triggering an MPC program execution via Ephemeral. Figure 2: The Carbyne stack components and the interfaces through which they communicate","title":"Communication Interfaces"},{"location":"getting-started/overview/#scalability","text":"A central design goal of Carbyne Stack is that each of the VCP services can be scaled independently and automatically. To achieve this, the Carbyne Stack microservices are implemented as Kubernetes services (Castor and Amphora) and as Knative applications (Ephemeral). This allows the scaling mechanisms of these platforms to be used to react dynamically to fluctuating load patterns.","title":"Scalability"},{"location":"getting-started/overview/#bibliography","text":"[1] Ivan Damg\u00e5rd, Valerio Pastro, Nigel Smart, Sarah Zakarias: Multiparty computation from somewhat homomorphic encryption . In: Safavi-Naini, R., Canetti, R. (eds.) Advances in Cryptology \u2013 CRYPTO 2012. Lecture Notes in Computer Science, vol. 7417, pp. 643\u2013662. Springer, Heidelberg, Germany, Santa Barbara, CA, USA (Aug 19\u201323, 2012) [2] Ivan Damg\u00e5rd, Kasper Damg\u00e5rd, Kurt Nielsen, Peter Sebastian Nordholt, Tomas Toft: Confidential Benchmarking based on Multiparty Computation . In Grossklags, J. and Preneel, B. (eds.) Financial Cryptography and Data Security, pp.169\u2013187. Springer. Only two-party settings are supported by Carbyne Stack as of now. \u21a9 Tuples must be generated externally and uploaded using the CLI as of today. A future release of Carbyne Stack will include a service called Klyshko to generate tuples in a scalable manner. \u21a9 Note that currently tuples baked into the container image are used by Ephemeral. Fetching the tuples from Castor will be implemented in a future release. \u21a9","title":"Bibliography"},{"location":"getting-started/platform-setup/","text":"Platform Setup Guide \u00b6 This guide describes how to prepare K8s clusters using kind that are suitable for deploying a two-party Carbyne Stack Virtual Cloud. After completing the steps described below, you should have two kind K8s clusters called apollo and starbuck with the following pods deployed: kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE default knative-operator-7fc877bffd-f9qdh 1 /1 Running 0 115s default postgres-operator-74f9948c5f-l8mpd 1 /1 Running 0 24s istio-operator istio-operator-6d7958b7bf-j5f78 1 /1 Running 0 4m10s istio-system istio-ingressgateway-7b757f7699-4sjk9 1 /1 Running 0 3m10s istio-system istiod-7556f7fddf-4gg6t 1 /1 Running 0 3m26s knative-serving activator-749f4f58bd-bvgvk 1 /1 Running 0 66s knative-serving autoscaler-848955c655-7ndxc 1 /1 Running 0 65s knative-serving controller-8c7b5f59c-d7brb 1 /1 Running 0 65s knative-serving istio-webhook-566b5df9f-6fhvt 1 /1 Running 0 61s knative-serving net-certmanager-webhook-5886f5f5cb-26sbr 1 /1 Running 0 59s knative-serving networking-certmanager-6b5cb4b9d6-c4gl2 1 /1 Running 0 60s knative-serving networking-istio-795f8cd665-27vcs 1 /1 Running 0 61s knative-serving webhook-5fd89bbf5-gghtq 1 /1 Running 0 64s kube-system coredns-66bff467f8-ht8hb 1 /1 Running 0 4m20s kube-system coredns-66bff467f8-vsndf 1 /1 Running 0 4m20s kube-system etcd-apollo-control-plane 1 /1 Running 0 4m30s kube-system kindnet-jht6w 1 /1 Running 0 4m20s kube-system kube-apiserver-apollo-control-plane 1 /1 Running 0 4m30s kube-system kube-controller-manager-apollo-control-plane 1 /1 Running 0 4m30s kube-system kube-proxy-w5dfw 1 /1 Running 0 4m20s kube-system kube-scheduler-apollo-control-plane 1 /1 Running 0 4m30s local-path-storage local-path-provisioner-59c6df4d-962pq 1 /1 Running 0 4m20s metallb-system controller-57f648cb96-vgtsp 1 /1 Running 0 3m15s metallb-system speaker-c8lq5 1 /1 Running 0 3m15s Prerequisites \u00b6 Warning Carbyne Stack has been tested using the exact versions of the tools specified below. Deviating from this battle tested configuration may create all kinds of issues. Do not forget to perform the post installation steps for Docker. Info You'll need at least 3 GB of memory and 1 CPU core per kind cluster to deploy Carbyne Stack. Depending on the actual workloads you are going to deploy, these numbers can be considerably higher. Docker Engine v20.10.6 Kind v0.11.0 kubectl v1.21.1 Helm v3.7.1 Setting up the Clusters \u00b6 Kind Clusters \u00b6 You will need two Carbyne Stack Virtual Cloud Providers deployed to separate K8s clusters to complete this getting started guide. The clusters are called apollo and starbuck . You can use the --name <name> option to launch a kind cluster with K8s context name kind-<name> , as follows: Apollo Starbuck kind create cluster --name apollo --image kindest/node:v1.18.19 kind create cluster --name starbuck --image kindest/node:v1.18.19 You can switch between the clusters easily using: Apollo Starbuck kubectl config use-context kind-apollo kubectl config use-context kind-starbuck Important Complete the remaining steps of this guide for the apollo cluster and then repeat for starbuck . Istio \u00b6 Install the Istio Operator v1.7.3 using: curl -L https://istio.io/downloadIstio | ISTIO_VERSION = 1 .7.3 TARGET_ARCH = x86_64 sh - helm install istio-operator istio-1.7.3/manifests/charts/istio-operator \\ --set operatorNamespace = istio-operator \\ --set watchedNamespaces = \"istio-system\" \\ --set hub = \"docker.io/istio\" \\ --set tag = \"1.7.3\" Create an Istio Control Plane in a dedicated namespace using: cat <<EOF > istio-control-plane.yaml apiVersion: v1 kind: Namespace metadata: name: istio-system --- apiVersion: install.istio.io/v1alpha1 kind: IstioOperator metadata: namespace: istio-system name: cs-istiocontrolplane spec: meshConfig: accessLogFile: /dev/stdout components: ingressGateways: - name: istio-ingressgateway enabled: true k8s: resources: requests: cpu: 10m memory: 40Mi service: ports: ## You can add custom gateway ports in user values overrides, # but it must include those ports since helm replaces. # Note that AWS ELB will by default perform health checks on # the first port on this list. Setting this to the health # check port will ensure that health checks always work. # https://github.com/istio/istio/issues/12503 - port: 15021 targetPort: 15021 name: status-port - port: 80 targetPort: 8080 name: http2 - port: 443 targetPort: 8443 name: https - port: 31400 targetPort: 31400 name: tcp # This is the port where sni routing happens - port: 15443 targetPort: 15443 name: tls - port: 30000 name: ephemeral-mpc-engine-port-0 - port: 30001 name: ephemeral-mpc-engine-port-1 - port: 30002 name: ephemeral-mpc-engine-port-2 - port: 30003 name: ephemeral-mpc-engine-port-3 - port: 30004 name: ephemeral-mpc-engine-port-4 pilot: k8s: env: - name: PILOT_TRACE_SAMPLING value: \"100\" resources: requests: cpu: 10m memory: 100Mi values: global: proxy: resources: requests: cpu: 10m memory: 40Mi pilot: autoscaleEnabled: false gateways: istio-egressgateway: autoscaleEnabled: false istio-ingressgateway: autoscaleEnabled: false EOF kubectl apply -f istio-control-plane.yaml MetalLB \u00b6 Install MetalLB v0.9.3 using: kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/namespace.yaml kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/metallb.yaml kubectl create secret generic -n metallb-system memberlist --from-literal = secretkey = \" $( openssl rand -base64 128 ) \" Configure MetalLB using: Apollo Starbuck export SUBNET = 172 .18.1.255/25 cat <<EOF | envsubst > metallb.yaml apiVersion: v1 kind: ConfigMap metadata: namespace: metallb-system name: config data: config: | address-pools: - name: default protocol: layer2 addresses: - ${SUBNET} avoid-buggy-ips: true EOF kubectl apply -f metallb.yaml export SUBNET = 172 .18.2.255/25 cat <<EOF | envsubst > metallb.yaml apiVersion: v1 kind: ConfigMap metadata: namespace: metallb-system name: config data: config: | address-pools: - name: default protocol: layer2 addresses: - ${SUBNET} avoid-buggy-ips: true EOF kubectl apply -f metallb.yaml Wait until an external IP has been assigned to the Istio Ingress Gateway by MetalLB: kubectl get services --namespace istio-system istio-ingressgateway -w The public IP eventually appears in column EXTERNAL-IP . Export the external IP for later use: export EXTERNAL_IP = $( kubectl get services --namespace istio-system istio-ingressgateway --output jsonpath = '{.status.loadBalancer.ingress[0].ip}' ) Knative \u00b6 Install the Knative Operator v0.19.0 using: kubectl apply -f https://github.com/knative/operator/releases/download/v0.19.0/operator.yaml Create a namespace for Knative Serving using: kubectl create namespace knative-serving Install the patched Knative Serving component with a sslip.io custom domain using: cat <<EOF | envsubst > knative-serving.yaml apiVersion: operator.knative.dev/v1alpha1 kind: KnativeServing metadata: name: knative-serving namespace: knative-serving spec: version: 0.19.0 manifests: - URL: https://github.com/carbynestack/serving/releases/download/v0.19.0_multiport-patch/serving-crds.yaml - URL: https://github.com/carbynestack/serving/releases/download/v0.19.0_multiport-patch/serving-core.yaml - URL: https://github.com/knative/net-istio/releases/download/v0.19.0/release.yaml - URL: https://github.com/knative/net-certmanager/releases/download/v0.19.0/release.yaml config: domain: ${EXTERNAL_IP}.sslip.io: \"\" EOF kubectl apply -f knative-serving.yaml Postgres Operator \u00b6 Deploy the Zalando Postgres operator v1.5.0 using: curl -sL https://github.com/zalando/postgres-operator/archive/refs/tags/v1.5.0.tar.gz | tar -xz helm install postgres-operator postgres-operator-1.5.0/charts/postgres-operator Clean Up \u00b6 If you no longer need the cluster you can tear it down using: Apollo Starbuck kind delete cluster --name apollo kind delete cluster --name starbuck Troubleshooting \u00b6 OpenVPN \u00b6 In case you use OpenVPN and encounter an error message when launching a kind cluster like ERROR: failed to create cluster: failed to ensure docker network: command \"docker network create -d=bridge -o com.docker.network.bridge.enable_ip_masquerade=true -o com.docker.network.driver.mtu=1500 --ipv6 --subnet fc00:f853:ccd:e793::/64 kind\" failed with error: exit status 1 Command Output: Error response from daemon: could not find an available, non-overlapping IPv4 address pool among the default follow the advice given here .","title":"Platform Setup"},{"location":"getting-started/platform-setup/#platform-setup-guide","text":"This guide describes how to prepare K8s clusters using kind that are suitable for deploying a two-party Carbyne Stack Virtual Cloud. After completing the steps described below, you should have two kind K8s clusters called apollo and starbuck with the following pods deployed: kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE default knative-operator-7fc877bffd-f9qdh 1 /1 Running 0 115s default postgres-operator-74f9948c5f-l8mpd 1 /1 Running 0 24s istio-operator istio-operator-6d7958b7bf-j5f78 1 /1 Running 0 4m10s istio-system istio-ingressgateway-7b757f7699-4sjk9 1 /1 Running 0 3m10s istio-system istiod-7556f7fddf-4gg6t 1 /1 Running 0 3m26s knative-serving activator-749f4f58bd-bvgvk 1 /1 Running 0 66s knative-serving autoscaler-848955c655-7ndxc 1 /1 Running 0 65s knative-serving controller-8c7b5f59c-d7brb 1 /1 Running 0 65s knative-serving istio-webhook-566b5df9f-6fhvt 1 /1 Running 0 61s knative-serving net-certmanager-webhook-5886f5f5cb-26sbr 1 /1 Running 0 59s knative-serving networking-certmanager-6b5cb4b9d6-c4gl2 1 /1 Running 0 60s knative-serving networking-istio-795f8cd665-27vcs 1 /1 Running 0 61s knative-serving webhook-5fd89bbf5-gghtq 1 /1 Running 0 64s kube-system coredns-66bff467f8-ht8hb 1 /1 Running 0 4m20s kube-system coredns-66bff467f8-vsndf 1 /1 Running 0 4m20s kube-system etcd-apollo-control-plane 1 /1 Running 0 4m30s kube-system kindnet-jht6w 1 /1 Running 0 4m20s kube-system kube-apiserver-apollo-control-plane 1 /1 Running 0 4m30s kube-system kube-controller-manager-apollo-control-plane 1 /1 Running 0 4m30s kube-system kube-proxy-w5dfw 1 /1 Running 0 4m20s kube-system kube-scheduler-apollo-control-plane 1 /1 Running 0 4m30s local-path-storage local-path-provisioner-59c6df4d-962pq 1 /1 Running 0 4m20s metallb-system controller-57f648cb96-vgtsp 1 /1 Running 0 3m15s metallb-system speaker-c8lq5 1 /1 Running 0 3m15s","title":"Platform Setup Guide"},{"location":"getting-started/platform-setup/#prerequisites","text":"Warning Carbyne Stack has been tested using the exact versions of the tools specified below. Deviating from this battle tested configuration may create all kinds of issues. Do not forget to perform the post installation steps for Docker. Info You'll need at least 3 GB of memory and 1 CPU core per kind cluster to deploy Carbyne Stack. Depending on the actual workloads you are going to deploy, these numbers can be considerably higher. Docker Engine v20.10.6 Kind v0.11.0 kubectl v1.21.1 Helm v3.7.1","title":"Prerequisites"},{"location":"getting-started/platform-setup/#setting-up-the-clusters","text":"","title":"Setting up the Clusters"},{"location":"getting-started/platform-setup/#kind-clusters","text":"You will need two Carbyne Stack Virtual Cloud Providers deployed to separate K8s clusters to complete this getting started guide. The clusters are called apollo and starbuck . You can use the --name <name> option to launch a kind cluster with K8s context name kind-<name> , as follows: Apollo Starbuck kind create cluster --name apollo --image kindest/node:v1.18.19 kind create cluster --name starbuck --image kindest/node:v1.18.19 You can switch between the clusters easily using: Apollo Starbuck kubectl config use-context kind-apollo kubectl config use-context kind-starbuck Important Complete the remaining steps of this guide for the apollo cluster and then repeat for starbuck .","title":"Kind Clusters"},{"location":"getting-started/platform-setup/#istio","text":"Install the Istio Operator v1.7.3 using: curl -L https://istio.io/downloadIstio | ISTIO_VERSION = 1 .7.3 TARGET_ARCH = x86_64 sh - helm install istio-operator istio-1.7.3/manifests/charts/istio-operator \\ --set operatorNamespace = istio-operator \\ --set watchedNamespaces = \"istio-system\" \\ --set hub = \"docker.io/istio\" \\ --set tag = \"1.7.3\" Create an Istio Control Plane in a dedicated namespace using: cat <<EOF > istio-control-plane.yaml apiVersion: v1 kind: Namespace metadata: name: istio-system --- apiVersion: install.istio.io/v1alpha1 kind: IstioOperator metadata: namespace: istio-system name: cs-istiocontrolplane spec: meshConfig: accessLogFile: /dev/stdout components: ingressGateways: - name: istio-ingressgateway enabled: true k8s: resources: requests: cpu: 10m memory: 40Mi service: ports: ## You can add custom gateway ports in user values overrides, # but it must include those ports since helm replaces. # Note that AWS ELB will by default perform health checks on # the first port on this list. Setting this to the health # check port will ensure that health checks always work. # https://github.com/istio/istio/issues/12503 - port: 15021 targetPort: 15021 name: status-port - port: 80 targetPort: 8080 name: http2 - port: 443 targetPort: 8443 name: https - port: 31400 targetPort: 31400 name: tcp # This is the port where sni routing happens - port: 15443 targetPort: 15443 name: tls - port: 30000 name: ephemeral-mpc-engine-port-0 - port: 30001 name: ephemeral-mpc-engine-port-1 - port: 30002 name: ephemeral-mpc-engine-port-2 - port: 30003 name: ephemeral-mpc-engine-port-3 - port: 30004 name: ephemeral-mpc-engine-port-4 pilot: k8s: env: - name: PILOT_TRACE_SAMPLING value: \"100\" resources: requests: cpu: 10m memory: 100Mi values: global: proxy: resources: requests: cpu: 10m memory: 40Mi pilot: autoscaleEnabled: false gateways: istio-egressgateway: autoscaleEnabled: false istio-ingressgateway: autoscaleEnabled: false EOF kubectl apply -f istio-control-plane.yaml","title":"Istio"},{"location":"getting-started/platform-setup/#metallb","text":"Install MetalLB v0.9.3 using: kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/namespace.yaml kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/metallb.yaml kubectl create secret generic -n metallb-system memberlist --from-literal = secretkey = \" $( openssl rand -base64 128 ) \" Configure MetalLB using: Apollo Starbuck export SUBNET = 172 .18.1.255/25 cat <<EOF | envsubst > metallb.yaml apiVersion: v1 kind: ConfigMap metadata: namespace: metallb-system name: config data: config: | address-pools: - name: default protocol: layer2 addresses: - ${SUBNET} avoid-buggy-ips: true EOF kubectl apply -f metallb.yaml export SUBNET = 172 .18.2.255/25 cat <<EOF | envsubst > metallb.yaml apiVersion: v1 kind: ConfigMap metadata: namespace: metallb-system name: config data: config: | address-pools: - name: default protocol: layer2 addresses: - ${SUBNET} avoid-buggy-ips: true EOF kubectl apply -f metallb.yaml Wait until an external IP has been assigned to the Istio Ingress Gateway by MetalLB: kubectl get services --namespace istio-system istio-ingressgateway -w The public IP eventually appears in column EXTERNAL-IP . Export the external IP for later use: export EXTERNAL_IP = $( kubectl get services --namespace istio-system istio-ingressgateway --output jsonpath = '{.status.loadBalancer.ingress[0].ip}' )","title":"MetalLB"},{"location":"getting-started/platform-setup/#knative","text":"Install the Knative Operator v0.19.0 using: kubectl apply -f https://github.com/knative/operator/releases/download/v0.19.0/operator.yaml Create a namespace for Knative Serving using: kubectl create namespace knative-serving Install the patched Knative Serving component with a sslip.io custom domain using: cat <<EOF | envsubst > knative-serving.yaml apiVersion: operator.knative.dev/v1alpha1 kind: KnativeServing metadata: name: knative-serving namespace: knative-serving spec: version: 0.19.0 manifests: - URL: https://github.com/carbynestack/serving/releases/download/v0.19.0_multiport-patch/serving-crds.yaml - URL: https://github.com/carbynestack/serving/releases/download/v0.19.0_multiport-patch/serving-core.yaml - URL: https://github.com/knative/net-istio/releases/download/v0.19.0/release.yaml - URL: https://github.com/knative/net-certmanager/releases/download/v0.19.0/release.yaml config: domain: ${EXTERNAL_IP}.sslip.io: \"\" EOF kubectl apply -f knative-serving.yaml","title":"Knative"},{"location":"getting-started/platform-setup/#postgres-operator","text":"Deploy the Zalando Postgres operator v1.5.0 using: curl -sL https://github.com/zalando/postgres-operator/archive/refs/tags/v1.5.0.tar.gz | tar -xz helm install postgres-operator postgres-operator-1.5.0/charts/postgres-operator","title":"Postgres Operator"},{"location":"getting-started/platform-setup/#clean-up","text":"If you no longer need the cluster you can tear it down using: Apollo Starbuck kind delete cluster --name apollo kind delete cluster --name starbuck","title":"Clean Up"},{"location":"getting-started/platform-setup/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"getting-started/platform-setup/#openvpn","text":"In case you use OpenVPN and encounter an error message when launching a kind cluster like ERROR: failed to create cluster: failed to ensure docker network: command \"docker network create -d=bridge -o com.docker.network.bridge.enable_ip_masquerade=true -o com.docker.network.driver.mtu=1500 --ipv6 --subnet fc00:f853:ccd:e793::/64 kind\" failed with error: exit status 1 Command Output: Error response from daemon: could not find an available, non-overlapping IPv4 address pool among the default follow the advice given here .","title":"OpenVPN"},{"location":"legal/branding-guidelines/","text":"Branding Guidelines \u00b6 The Carbyne Stack trademark (hereinafter referred to as \"Carbyne Stack Trademarks\") is a trademark of Robert Bosch GmbH , and is treated separately from the copyright and patent license grants contained in the Carbyne Stack repositories on GitHub. Important Any use of the Carbyne Stack Trademarks other than those explicitly permitted in these guidelines must be approved by Robert Bosch GmbH in advance (for getting in touch please see the contact information ). Acceptable Uses \u00b6 Carbyne Stack is an open project. You may use the Carbyne Stack Trademarks to refer to the project without prior written permission in accordance with the guidelines specified in this document. Uses that do not require prior approval are the following: Give reference to the Carbyne Stack project itself Link to the carbynestack.io website Refer to original source code or other files shared by the Carbyne Stack repositories on GitHub Blog posts, news articles, or educational materials about Carbyne Stack Uses Subject to Approval \u00b6 Exemplary uses of the Carbyne Stack Trademarks that do require prior approval by Robert Bosch GmbH are the following (non-exhaustive list): Use as or integrate as part of your application icon or other design elements Create and use a modified or derived version Refer to modified versions of the Carbyne Stack platform including but not limited to forks Robert Bosch GmbH reserves the right to deny trademark permission for certain use cases if the use case is not in the interest of the Carbyne Stack Community.","title":"Branding Guidelines"},{"location":"legal/branding-guidelines/#branding-guidelines","text":"The Carbyne Stack trademark (hereinafter referred to as \"Carbyne Stack Trademarks\") is a trademark of Robert Bosch GmbH , and is treated separately from the copyright and patent license grants contained in the Carbyne Stack repositories on GitHub. Important Any use of the Carbyne Stack Trademarks other than those explicitly permitted in these guidelines must be approved by Robert Bosch GmbH in advance (for getting in touch please see the contact information ).","title":"Branding Guidelines"},{"location":"legal/branding-guidelines/#acceptable-uses","text":"Carbyne Stack is an open project. You may use the Carbyne Stack Trademarks to refer to the project without prior written permission in accordance with the guidelines specified in this document. Uses that do not require prior approval are the following: Give reference to the Carbyne Stack project itself Link to the carbynestack.io website Refer to original source code or other files shared by the Carbyne Stack repositories on GitHub Blog posts, news articles, or educational materials about Carbyne Stack","title":"Acceptable Uses"},{"location":"legal/branding-guidelines/#uses-subject-to-approval","text":"Exemplary uses of the Carbyne Stack Trademarks that do require prior approval by Robert Bosch GmbH are the following (non-exhaustive list): Use as or integrate as part of your application icon or other design elements Create and use a modified or derived version Refer to modified versions of the Carbyne Stack platform including but not limited to forks Robert Bosch GmbH reserves the right to deny trademark permission for certain use cases if the use case is not in the interest of the Carbyne Stack Community.","title":"Uses Subject to Approval"},{"location":"legal/corporate-information/","text":"Corporate Information \u00b6 Name and Address \u00b6 Robert Bosch GmbH Robert-Bosch-Platz 1 70839 Gerlingen-Schillerh\u00f6he GERMANY Members of the Board of Management \u00b6 Dr. Stefan Hartung, Dr. Christian Fischer, Filiz Albrecht, Dr. Markus Forschner, Dr. Markus Heyn, Rolf Najork Your contact at Robert Bosch GmbH \u00b6 Carbyne Stack Maintainers rng_cr_carbynestack@bosch.com +49(711)811-0 Register Entries \u00b6 Registration Court: District Court Stuttgart HRB 14000 Value-added tax identification number \u00b6 DE811128135","title":"Corporate Information"},{"location":"legal/corporate-information/#corporate-information","text":"","title":"Corporate Information"},{"location":"legal/corporate-information/#name-and-address","text":"Robert Bosch GmbH Robert-Bosch-Platz 1 70839 Gerlingen-Schillerh\u00f6he GERMANY","title":"Name and Address"},{"location":"legal/corporate-information/#members-of-the-board-of-management","text":"Dr. Stefan Hartung, Dr. Christian Fischer, Filiz Albrecht, Dr. Markus Forschner, Dr. Markus Heyn, Rolf Najork","title":"Members of the Board of Management"},{"location":"legal/corporate-information/#your-contact-at-robert-bosch-gmbh","text":"Carbyne Stack Maintainers rng_cr_carbynestack@bosch.com +49(711)811-0","title":"Your contact at Robert Bosch GmbH"},{"location":"legal/corporate-information/#register-entries","text":"Registration Court: District Court Stuttgart HRB 14000","title":"Register Entries"},{"location":"legal/corporate-information/#value-added-tax-identification-number","text":"DE811128135","title":"Value-added tax identification number"},{"location":"legal/export-control/","text":"Export Control \u00b6 Carbyne Stack includes cryptographic software. The country in which you currently reside may have restrictions on the import, possession, use, and/or re-export to another country, of encryption software. Before using any encryption software, please check your country's laws, regulations and policies concerning the import, possession, or use, and re-export of encryption software, to see if this is permitted. See the Wassenaar Arrangement website for more information. Robert Bosch GmbH has classified this software as Export Commodity Control Number (ECCN) 5D002, which includes information security software using or performing cryptographic functions with asymmetric algorithms. The form and manner of this distribution makes it eligible for export under the \"publicly available\" Section 742.15(b) and 734.3(b)(3) exemptions (see the BIS Export Administration Regulations, Section 742.15(b) and Section 734.3(b)(3)) for both object code and source code. The following export control compliance notifications have been delivered to crypt@bis.doc.gov and enc@nsa.gov as of the dates set forth below. Key Value Project Carbyne Stack Sent 2021-07-21 SUBMISSION TYPE EAR 742.15(b) and 734.3(b)(3) SUBMITTED BY Sven Trieflinger SUBMITTED FOR Robert Bosch GmbH POINT OF CONTACT Sven Trieflinger MANUFACTURER(S) Robert Bosch GmbH PRODUCT NAME/MODEL Carbyne Stack Project ECCN 5D002 INTERNET LOCATION(S) https://carbynestack.io , https://github.com/carbynestack","title":"Export Control"},{"location":"legal/export-control/#export-control","text":"Carbyne Stack includes cryptographic software. The country in which you currently reside may have restrictions on the import, possession, use, and/or re-export to another country, of encryption software. Before using any encryption software, please check your country's laws, regulations and policies concerning the import, possession, or use, and re-export of encryption software, to see if this is permitted. See the Wassenaar Arrangement website for more information. Robert Bosch GmbH has classified this software as Export Commodity Control Number (ECCN) 5D002, which includes information security software using or performing cryptographic functions with asymmetric algorithms. The form and manner of this distribution makes it eligible for export under the \"publicly available\" Section 742.15(b) and 734.3(b)(3) exemptions (see the BIS Export Administration Regulations, Section 742.15(b) and Section 734.3(b)(3)) for both object code and source code. The following export control compliance notifications have been delivered to crypt@bis.doc.gov and enc@nsa.gov as of the dates set forth below. Key Value Project Carbyne Stack Sent 2021-07-21 SUBMISSION TYPE EAR 742.15(b) and 734.3(b)(3) SUBMITTED BY Sven Trieflinger SUBMITTED FOR Robert Bosch GmbH POINT OF CONTACT Sven Trieflinger MANUFACTURER(S) Robert Bosch GmbH PRODUCT NAME/MODEL Carbyne Stack Project ECCN 5D002 INTERNET LOCATION(S) https://carbynestack.io , https://github.com/carbynestack","title":"Export Control"},{"location":"legal/privacy-policy/","text":"Privacy Policy \u00b6 GitHub Pages Service \u00b6 This Website is hosted as a GitHub Pages website. GitHub may collect User Personal Information from visitors to this GitHub Pages website, including logs of visitor IP addresses, to comply with legal obligations, and to maintain the security and integrity of this Website and the Service. See the GitHub Privacy Statement for details. Data Collection \u00b6 Website Analytics \u00b6 We want to process as little personal information as possible when you use our website. That's why we've chosen Fathom Analytics for our website analytics, which doesn't use cookies and complies with the GDPR, ePrivacy (including PECR), COPPA and CCPA. Using this privacy-friendly website analytics software, your IP address is only briefly processed, and we (running this website) have no way of identifying you. As per the CCPA, your personal information is de-identified. You can read more about this on Fathom Analytics' website . The purpose of us using this software is to understand our website traffic in the most privacy-friendly way possible so that we can continually improve our website and business. The lawful basis as per the GDPR is \"f); where our legitimate interests are to improve the Carbyne Stack website and open source project continually.\" As per the explanation, no personal data is stored over time. Cookie Usage \u00b6 This Website does not use cookies. Linked services \u00b6 This website contains links to other services. If you follow these links, you should become aware of their terms of service. We link to: GitHub for documentation and source code repositories. Additional links might occur in the documentation.","title":"Privacy Policy"},{"location":"legal/privacy-policy/#privacy-policy","text":"","title":"Privacy Policy"},{"location":"legal/privacy-policy/#github-pages-service","text":"This Website is hosted as a GitHub Pages website. GitHub may collect User Personal Information from visitors to this GitHub Pages website, including logs of visitor IP addresses, to comply with legal obligations, and to maintain the security and integrity of this Website and the Service. See the GitHub Privacy Statement for details.","title":"GitHub Pages Service"},{"location":"legal/privacy-policy/#data-collection","text":"","title":"Data Collection"},{"location":"legal/privacy-policy/#website-analytics","text":"We want to process as little personal information as possible when you use our website. That's why we've chosen Fathom Analytics for our website analytics, which doesn't use cookies and complies with the GDPR, ePrivacy (including PECR), COPPA and CCPA. Using this privacy-friendly website analytics software, your IP address is only briefly processed, and we (running this website) have no way of identifying you. As per the CCPA, your personal information is de-identified. You can read more about this on Fathom Analytics' website . The purpose of us using this software is to understand our website traffic in the most privacy-friendly way possible so that we can continually improve our website and business. The lawful basis as per the GDPR is \"f); where our legitimate interests are to improve the Carbyne Stack website and open source project continually.\" As per the explanation, no personal data is stored over time.","title":"Website Analytics"},{"location":"legal/privacy-policy/#cookie-usage","text":"This Website does not use cookies.","title":"Cookie Usage"},{"location":"legal/privacy-policy/#linked-services","text":"This website contains links to other services. If you follow these links, you should become aware of their terms of service. We link to: GitHub for documentation and source code repositories. Additional links might occur in the documentation.","title":"Linked services"}]}